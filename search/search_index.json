{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Pattern Analyzer","text":"<p>This site provides comprehensive documentation for the Pattern Analyzer framework, covering user guides, API references, and plugin development.</p> <p>Pattern Analyzer is a powerful, plugin-based framework designed for the analysis of binary data. Whether you're a security researcher, a data scientist, or a developer, Pattern Analyzer provides the tools to dissect binary files, detect patterns, and assess randomness through a suite of statistical and analytical tools.</p>"},{"location":"#quick-navigation","title":"Quick Navigation","text":"<ul> <li>Getting Started: A quick-start guide to install Pattern Analyzer and run your first analysis.</li> <li>User Guide: Detailed instructions on using the CLI, Web UI, and configuration files.</li> <li>Plugin Developer Guide: Learn how to create your own tests, transforms, and visualizers.</li> <li>API Reference: A reference for using Pattern Analyzer programmatically in your own Python scripts.</li> <li>Test Reference: A detailed catalog of all built-in analysis plugins.</li> <li>Configuration Examples: See examples of <code>YAML</code> and <code>JSON</code> configuration files.</li> </ul>"},{"location":"#running-the-documentation-locally","title":"Running the Documentation Locally","text":"<p>To browse this documentation site on your local machine, ensure you have MkDocs and the Material theme installed.</p> <pre><code># Install required packages (preferably in a virtual environment)\npip install mkdocs mkdocs-material\n\n# Serve the documentation site\nmkdocs serve\n</code></pre> <p>This will start a local web server, and you can view the site by navigating to <code>http://127.0.0.1:8000</code> in your browser.</p>"},{"location":"api-reference/","title":"API Reference","text":"<p>This page provides a reference for the programmatic use of the Pattern Analyzer Python API. It is intended for developers who want to integrate Pattern Analyzer's analysis capabilities into their own applications.</p>"},{"location":"api-reference/#core-components","title":"Core Components","text":"<p>The API revolves around a few key classes defined in <code>patternanalyzer.engine</code> and <code>patternanalyzer.plugin_api</code>.</p>"},{"location":"api-reference/#engine","title":"<code>Engine</code>","text":"<p>The <code>Engine</code> class is the main entry point for all analysis tasks.</p> <pre><code>from patternanalyzer.engine import Engine\n\n# Initialize the engine. This automatically discovers installed plugins.\nengine = Engine()\n</code></pre>"},{"location":"api-reference/#engineanalyzeinput_bytes-bytes-config-dict-dict","title":"<code>engine.analyze(input_bytes: bytes, config: dict) -&gt; dict</code>","text":"<p>Performs a full analysis on a byte string.</p> <ul> <li><code>input_bytes</code>: The binary data to analyze.</li> <li><code>config</code>: A dictionary specifying the analysis pipeline (transforms, tests, settings).</li> <li>Returns: A dictionary containing the <code>results</code>, <code>scorecard</code>, and <code>meta</code> information.</li> </ul> <p>Example:</p> <pre><code>output = engine.analyze(\n    b'\\x00\\x01\\x02' * 100,\n    config={\"tests\": [{\"name\": \"monobit\"}]}\n)\n</code></pre>"},{"location":"api-reference/#engineanalyze_streamstream_iterable-config-dict-dict","title":"<code>engine.analyze_stream(stream_iterable, config: dict) -&gt; dict</code>","text":"<p>Performs analysis on a stream of data (an iterable of <code>bytes</code>). This is memory-efficient for large files. Only plugins that implement the streaming API (<code>update</code>/<code>finalize</code>) will run.</p> <p>Example:</p> <pre><code>def file_stream(path, chunk_size=4096):\n    with open(path, \"rb\") as f:\n        while chunk := f.read(chunk_size):\n            yield chunk\n\nstream = file_stream(\"large_file.bin\")\noutput = engine.analyze_stream(stream, config={\"tests\": [{\"name\": \"monobit\"}]})\n</code></pre>"},{"location":"api-reference/#engineget_available_tests-liststr","title":"<code>engine.get_available_tests() -&gt; list[str]</code>","text":"<p>Returns a list of names of all registered test plugins.</p>"},{"location":"api-reference/#bytesview","title":"<code>BytesView</code>","text":"<p>A memory-efficient wrapper for binary data passed to plugins. It's the primary data type used within the <code>run</code> method of plugins.</p> <pre><code>from patternanalyzer.plugin_api import BytesView\n\ndata = BytesView(b'\\xAA\\xBB\\xCC')\n\n# Get the data back as bytes\nraw_bytes = data.to_bytes()\n\n# Get a view of the data as a list of bits (0s and 1s)\nbits = data.bit_view()\n# bits will be [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, ...]\n</code></pre>"},{"location":"api-reference/#testresult","title":"<code>TestResult</code>","text":"<p>A dataclass used by <code>TestPlugin</code> instances to return their findings.</p> <pre><code>from patternanalyzer.plugin_api import TestResult\n\n# Example of creating a TestResult within a plugin\nresult = TestResult(\n    test_name=\"my_custom_test\",\n    passed=True,\n    p_value=0.98,\n    category=\"statistical\",\n    metrics={\"key_statistic\": 123.45}\n)```\n\n## Full API Example\n\nThis example demonstrates initializing the engine, defining a custom analysis pipeline, and running the analysis.\n\n```python\nfrom patternanalyzer.engine import Engine\nimport json\nimport os\n\n# --- 1. Setup ---\n# Initialize the engine\nengine = Engine()\n\n# Prepare some sample data\n# Highly non-random data (repeating pattern)\nsample_data = b'\\x10\\x20\\x30' * 1000\n\n# --- 2. Configure the Analysis ---\n# We want to apply a transform and then run a few specific tests.\nanalysis_config = {\n    # Apply an XOR transform with key 0x42 first\n    \"transforms\": [\n        {\n            \"name\": \"xor_const\", \n            \"params\": {\"xor_value\": 0x42}\n        }\n    ],\n    # Run these tests on the transformed data\n    \"tests\": [\n        {\"name\": \"monobit\"},\n        {\"name\": \"runs\"},\n        {\"name\": \"ecb_detector\"}\n    ],\n    # Set a global significance level for FDR correction\n    \"fdr_q\": 0.05,\n    # Generate an HTML report\n    \"html_report\": \"api_report.html\"\n}\n\n# --- 3. Run and Process Results ---\nprint(\"Starting analysis...\")\noutput = engine.analyze(sample_data, analysis_config)\nprint(\"Analysis complete.\")\n\n# Save the full JSON report\nwith open(\"api_report.json\", \"w\") as f:\n    json.dump(output, f, indent=2)\n\n# Print a summary from the scorecard\nscorecard = output.get(\"scorecard\", {})\nprint(f\"\\n--- Scorecard Summary ---\")\nprint(f\"Failed Tests (FDR Rejected): {scorecard.get('failed_tests')}\")\nprint(f\"Total Tests Run: {scorecard.get('total_tests')}\")\nprint(f\"HTML report generated at: {os.path.abspath('api_report.html')}\")\n</code></pre>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This guide will walk you through the basic steps to set up Pattern Analyzer and perform your first analysis.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or newer.</li> <li><code>git</code> for cloning the repository.</li> </ul>"},{"location":"getting-started/#installation","title":"Installation","text":"<p>First, clone the repository and set up a Python virtual environment.</p> <pre><code># Clone the repository\ngit clone https://github.com/edgetype/pattern-analyzer.git\ncd pattern-analyzer\n\n# Create and activate a virtual environment\npython -m venv .venv\n# On Windows: .venv\\Scripts\\activate\n# On macOS/Linux: source .venv/bin/activate\n\n# Install the project in editable mode with all optional dependencies\npip install -e .[test,ml,ui]\n</code></pre> <p>This command installs Pattern Analyzer and all dependencies required for the user interfaces, machine learning plugins, and running tests.</p>"},{"location":"getting-started/#running-your-first-analysis-cli","title":"Running Your First Analysis (CLI)","text":"<p>The Command-Line Interface (CLI) is the quickest way to analyze a file. Let's analyze the provided <code>test.bin</code> file.</p> <pre><code># Run analysis on a file and save the output to report.json\npatternanalyzer analyze test.bin --out report.json\n</code></pre> <p>After the command completes, a <code>report.json</code> file will be created in your directory. It contains a detailed breakdown of the results from all default tests.</p> <pre><code>{\n  \"results\": [\n    {\n      \"test_name\": \"monobit\",\n      \"passed\": true,\n      \"p_value\": 0.53,\n      \"...\": \"...\"\n    }\n  ],\n  \"scorecard\": {\n    \"failed_tests\": 0,\n    \"...\": \"...\"\n  },\n  \"meta\": {\n    \"...\": \"...\"\n  }\n}\n</code></pre>"},{"location":"getting-started/#using-the-python-api","title":"Using the Python API","text":"<p>For more advanced use cases, you can integrate Pattern Analyzer directly into your Python scripts.</p> <p>Create a file named <code>example.py</code> with the following content:</p> <pre><code>from patternanalyzer.engine import Engine\nimport json\n\n# 1. Initialize the analysis engine\nengine = Engine()\n\n# 2. Define the data to be analyzed\ndata_bytes = b'\\x55\\xAA' * 128  # A simple alternating pattern\n\n# 3. Create a configuration for the analysis\n#    We will run two simple tests: 'monobit' and 'runs'\nconfig = {\n    \"tests\": [\n        {\"name\": \"monobit\"},\n        {\"name\": \"runs\"}\n    ]\n}\n\n# 4. Run the analysis\noutput = engine.analyze(data_bytes, config)\n\n# 5. Print the scorecard\nprint(\"Analysis Scorecard:\")\nprint(json.dumps(output.get('scorecard'), indent=2))\n</code></pre> <p>Run the script from your terminal:</p> <pre><code>python example.py\n</code></pre>"},{"location":"getting-started/#launching-the-web-ui","title":"Launching the Web UI","text":"<p>Pattern Analyzer includes a user-friendly web interface built with Streamlit for interactive analysis.</p> <p>To start it, run the following command in your terminal:</p> <pre><code>streamlit run app.py\n</code></pre> <p>Now, open your web browser and navigate to the local URL displayed in the terminal (usually <code>http://localhost:8501</code>). You can upload files, select tests, and view results interactively.</p>"},{"location":"plugin-developer-guide/","title":"Plugin Developer Guide","text":"<p>Pattern Analyzer's power comes from its extensible plugin architecture. This guide explains how to create your own plugins.</p>"},{"location":"plugin-developer-guide/#core-concepts","title":"Core Concepts","text":"<p>There are three types of plugins, all inheriting from base classes defined in <code>patternanalyzer/plugin_api.py</code>:</p> <ol> <li><code>TransformPlugin</code>: Modifies the input data before it is passed to the test plugins. Examples include XORing, decoding, or decryption.</li> <li><code>TestPlugin</code>: The core analysis unit. It inspects the data and returns a <code>TestResult</code> object with findings.</li> <li><code>VisualPlugin</code>: Generates a visual artifact (like an SVG or PNG) based on a <code>TestResult</code> from another plugin.</li> </ol>"},{"location":"plugin-developer-guide/#key-data-structures","title":"Key Data Structures","text":"<ul> <li><code>BytesView</code>: A memory-efficient wrapper around the input data (<code>bytes</code> or <code>memoryview</code>). It provides helpful methods like <code>.bit_view()</code> to get a sequence of bits without extra copies.</li> <li><code>TestResult</code>: A dataclass that holds the output of a <code>TestPlugin</code>. It includes fields like <code>test_name</code>, <code>passed</code>, <code>p_value</code>, and a <code>metrics</code> dictionary for detailed statistics.</li> </ul>"},{"location":"plugin-developer-guide/#creating-a-simple-test-plugin","title":"Creating a Simple Test Plugin","text":"<p>Let's create a new <code>TestPlugin</code> that checks if the data consists entirely of null bytes.</p> <ol> <li> <p>Create the Plugin File</p> <p>Create a new file <code>patternanalyzer/plugins/all_zeros.py</code>:</p> <p>```python from patternanalyzer.plugin_api import TestPlugin, TestResult, BytesView</p> <p>class AllZerosTest(TestPlugin):     \"\"\"A simple diagnostic test to check for all-zero data.\"\"\"</p> <pre><code>def describe(self) -&gt; str:\n    return \"Checks if the data consists entirely of null bytes.\"\n\ndef run(self, data: BytesView, params: dict) -&gt; TestResult:\n    # Get the raw bytes from the BytesView\n    input_bytes = data.to_bytes()\n\n    # Check if there are any non-zero bytes\n    is_all_zeros = not any(input_bytes)\n\n    # For a diagnostic test, we don't produce a p-value.\n    # 'passed' is subjective; here we'll say it \"passes\" if it's NOT all zeros.\n    return TestResult(\n        test_name=\"all_zeros\",\n        passed=not is_all_zeros,\n        p_value=None,  # This is a diagnostic, not statistical, test\n        category=\"diagnostic\",\n        metrics={\n            \"total_bytes\": len(input_bytes),\n            \"is_all_zeros\": is_all_zeros\n        }\n    )\n</code></pre> <p>```</p> </li> <li> <p>Register the Plugin</p> <p>The easiest way to make your plugin discoverable is by adding an entry point to <code>pyproject.toml</code> under the <code>[project.entry-points.\"patternanalyzer.plugins\"]</code> section.</p> <p>```toml</p> </li> </ol>"},{"location":"plugin-developer-guide/#in-pyprojecttoml","title":"In pyproject.toml","text":"<p>[project.entry-points.\"patternanalyzer.plugins\"] all_zeros = \"patternanalyzer.plugins.all_zeros:AllZerosTest\"</p>"},{"location":"plugin-developer-guide/#other-plugins","title":"... other plugins","text":"<p>```</p> <p>After adding the entry point, reinstall the package in editable mode for the changes to take effect: <code>bash pip install -e .</code> The Pattern Analyzer engine will now automatically discover and register your new plugin at startup.</p>"},{"location":"plugin-developer-guide/#supporting-streaming-analysis","title":"Supporting Streaming Analysis","text":"<p>For plugins that can process data in chunks, you can implement the streaming API by overriding the <code>update</code> and <code>finalize</code> methods. This is memory-efficient for large files.</p> <ul> <li><code>update(self, chunk: bytes, params: dict)</code>: This method is called for each chunk of data from the stream. Your plugin should update its internal state here.</li> <li><code>finalize(self, params: dict) -&gt; TestResult</code>: Called after all chunks have been processed. This method should compute the final result based on the accumulated state and then reset the state for the next run.</li> </ul> <p>See <code>patternanalyzer/plugins/monobit.py</code> for a simple example of a test that supports both batch (<code>run</code>) and streaming (<code>update</code>/<code>finalize</code>) modes.</p>"},{"location":"plugin-developer-guide/#writing-unit-tests","title":"Writing Unit Tests","text":"<p>It's crucial to write tests for your new plugin. Add a new test file in the <code>tests/</code> directory, for example, <code>tests/test_all_zeros.py</code>.</p> <pre><code>from patternanalyzer.plugins.all_zeros import AllZerosTest\nfrom patternanalyzer.plugin_api import BytesView\n\ndef test_all_zeros_positive():\n    plugin = AllZerosTest()\n    data = BytesView(b'\\x00\\x00\\x00\\x00')\n    result = plugin.run(data, {})\n    assert result.passed is False\n    assert result.metrics[\"is_all_zeros\"] is True\n\ndef test_all_zeros_negative():\n    plugin = AllZerosTest()\n    data = BytesView(b'\\x00\\x01\\x00\\x00')\n    result = plugin.run(data, {})\n    assert result.passed is True\n    assert result.metrics[\"is_all_zeros\"] is False\n</code></pre> <p>Run the test suite to ensure your plugin works as expected:</p> <pre><code>pytest\n</code></pre>"},{"location":"test-reference/","title":"Test Reference","text":"<p>This document provides a reference for the built-in test and analysis plugins available in Pattern Analyzer.</p>"},{"location":"test-reference/#plugin-categories","title":"Plugin Categories","text":"<p>Plugins are broadly grouped into the following categories:</p> <ul> <li>Statistical Tests: Classic tests for randomness, many inspired by the NIST SP 800-22 test suite.</li> <li>Cryptographic Analysis: Plugins that search for patterns related to cryptographic algorithms.</li> <li>Structural Analysis: Plugins that parse and analyze the structure of common file formats.</li> <li>Machine Learning-Based: Plugins that use ML models for anomaly detection or classification.</li> <li>Diagnostic &amp; Information Theory: Plugins that provide metrics like entropy, complexity, or visualizations without a formal pass/fail result.</li> </ul>"},{"location":"test-reference/#statistical-tests","title":"Statistical Tests","text":"<p>These plugins produce a <code>p_value</code>. A result is typically considered \"failed\" if the p-value is below the configured significance level (e.g., 0.01) and is rejected by the False Discovery Rate (FDR) correction.</p> Plugin Name Description <code>monobit</code> Checks the proportion of zeros and ones. A fundamental test for bias. <code>runs</code> Counts the number of \"runs\" (uninterrupted sequences of identical bits) to check for oscillation speed. <code>block_frequency</code> Checks the frequency of ones within fixed-size blocks of the data. <code>frequency_within_block</code> A variant of the block frequency test aligned with the NIST specification. <code>longest_run</code> Finds the longest run of ones within blocks and checks its distribution. <code>serial</code> Checks the frequency of all possible overlapping m-bit patterns to find biases. <code>cusum</code> Cumulative Sums test; detects if the cumulative sum of the random walk strays too far from zero. <code>approximate_entropy</code> Measures the predictability and regularity of the sequence. <code>maurers_universal</code> A test based on the compressibility of the sequence; less compressible data is more random. <code>non_overlapping_template_matching</code> Counts non-overlapping occurrences of a specific bit pattern. <code>overlapping_template_matching</code> Counts overlapping occurrences of a specific bit pattern. <code>random_excursions</code> Analyzes the number of visits to various states in a random walk. <code>random_excursions_variant</code> A variant of the random excursions test. <code>binary_matrix_rank</code> Forms binary matrices from the data and checks the distribution of their ranks. <code>nist_dft_spectral</code> Uses the Discrete Fourier Transform to detect periodic features in the data. <code>diehard_birthday_spacings</code> A test from the Diehard suite that examines the spacing between repeated values. <code>diehard_overlapping_sums</code> A test from the Diehard suite based on the distribution of sums of overlapping words. <code>diehard_3d_spheres</code> A test from the Diehard suite that places points in a 3D cube and checks distribution. <code>testu01_smallcrush</code> An adapter for a subset of the powerful TestU01 SmallCrush battery of tests."},{"location":"test-reference/#cryptographic-analysis","title":"Cryptographic Analysis","text":"Plugin Name Description <code>ecb_detector</code> Detects repeating, fixed-size blocks, a strong indicator of Electronic Codebook (ECB) mode encryption. <code>frequency_pattern</code> Performs frequency analysis and uses Index of Coincidence (IoC) to guess repeating-key XOR key lengths. <code>known_constants_search</code> Scans the data for known cryptographic constants, such as the AES S-box. <code>linear_complexity</code> Determines the length of the shortest Linear Feedback Shift Register (LFSR) that can generate the sequence."},{"location":"test-reference/#structural-analysis","title":"Structural Analysis","text":"<p>These plugins check if the data conforms to a known file format structure.</p> Plugin Name Description <code>magic_detector</code> Checks the first few bytes for common file \"magic numbers\" (e.g., PNG, ZIP). <code>png_structure</code> Parses the chunk structure of a PNG file. <code>pdf_structure</code> Performs a lightweight analysis of a PDF file's object structure. <code>zip_structure</code> Parses local file headers and central directory entries from a ZIP archive."},{"location":"test-reference/#machine-learning-based","title":"Machine Learning-Based","text":"<p>These plugins use trained models or ML heuristics for analysis. They may require the <code>[ml]</code> extra dependencies to be installed.</p> Plugin Name Description <code>autoencoder_anomaly</code> Uses an autoencoder model to detect anomalies based on reconstruction error. <code>lstm_gru_anomaly</code> Uses a recurrent neural network (LSTM/GRU) to detect anomalies in time-series data. <code>classifier_labeler</code> Uses a pre-trained classifier to label the data (e.g., \"encrypted\", \"ransomware\")."},{"location":"test-reference/#diagnostic-information-theory","title":"Diagnostic &amp; Information Theory","text":"<p>These plugins provide quantitative metrics or visualizations rather than a formal p-value.</p> Plugin Name Description <code>autocorrelation</code> Computes the correlation of the sequence with shifted versions of itself. <code>dft_spectral_advanced</code> A more advanced spectral test that checks if the power spectrum follows an exponential distribution. <code>dotplot</code> Creates a 2D self-similarity matrix to visualize repeating patterns. <code>fft_spectral</code> A diagnostic FFT-based test that reports the Signal-to-Noise Ratio (SNR) of the highest spectral peak. <code>hurst_exponent</code> Estimates the Hurst exponent, a measure of long-range dependence or \"memory\" in the sequence. <code>lz_complexity</code> Measures complexity based on the number of phrases in an LZ78-style compression parse. <code>conditional_entropy</code> Calculates the conditional entropy H(Y|X) between adjacent symbols. <code>mutual_information</code> Calculates the mutual information I(X;Y) between adjacent symbols. <code>transfer_entropy</code> A proxy for transfer entropy, equivalent to mutual information for a single stream."},{"location":"user-guide/","title":"User Guide","text":"<p>This guide provides a more in-depth look at how to use Pattern Analyzer's various features and interfaces.</p>"},{"location":"user-guide/#1-command-line-interface-cli","title":"1. Command-Line Interface (CLI)","text":"<p>The <code>patternanalyzer</code> CLI is the primary tool for automated analysis. The main command is <code>analyze</code>.</p>"},{"location":"user-guide/#basic-usage","title":"Basic Usage","text":"<pre><code>patternanalyzer analyze &lt;input_file&gt; [options]\n</code></pre>"},{"location":"user-guide/#key-options","title":"Key Options","text":"<ul> <li><code>-o, --out &lt;path&gt;</code>: Specifies the path for the output JSON report. Defaults to <code>report.json</code>.</li> <li><code>-c, --config &lt;path&gt;</code>: Path to a <code>JSON</code> or <code>YAML</code> configuration file to customize the analysis pipeline.</li> <li><code>--profile &lt;name&gt;</code>: Use a built-in analysis profile. Available profiles: <code>quick</code>, <code>nist</code>, <code>crypto</code>, <code>full</code>. This is an easy way to run a focused set of tests.</li> <li><code>--xor-value &lt;0-255&gt;</code>: Applies a single-byte XOR transformation to the data before running tests.</li> <li><code>--html-report &lt;path&gt;</code>: Generates a standalone HTML report in addition to the JSON output.</li> </ul> <p>Example with a profile and HTML report:</p> <pre><code>patternanalyzer analyze suspicious.dat --profile crypto --html-report report.html\n</code></pre>"},{"location":"user-guide/#2-configuration-files","title":"2. Configuration Files","text":"<p>For full control over the analysis, you can use a configuration file in <code>YAML</code> or <code>JSON</code> format.</p>"},{"location":"user-guide/#structure","title":"Structure","text":"<p>A configuration file can specify transforms, tests, and global settings.</p> <p>Example (<code>config.yml</code>):</p> <pre><code># 1. A list of transformations to apply in sequence\ntransforms:\n  - name: xor_const\n    params:\n      xor_value: 85 # 0x55 in decimal\n\n# 2. A list of tests to run on the transformed data\ntests:\n  - name: monobit\n  - name: runs\n    params:\n      min_bits: 100 # Custom parameter for the runs test\n  - name: ecb_detector\n    params:\n      block_size: 16\n\n# 3. Global settings\nfdr_q: 0.05 # False Discovery Rate significance level (q-value)\n</code></pre> <p>To use this file:</p> <pre><code>patternanalyzer analyze my_file.bin --config config.yml\n</code></pre>"},{"location":"user-guide/#3-web-user-interface-streamlit","title":"3. Web User Interface (Streamlit)","text":"<p>The web UI provides an interactive way to upload files, select tests and transforms, and view results, including visualizations.</p> <p>To launch the Web UI:</p> <pre><code>streamlit run app.py\n</code></pre> <p>Or, if <code>[ui]</code> extras are installed:</p> <pre><code>patternanalyzer serve-ui\n</code></pre> <p>Navigate to the URL shown in your terminal to access the interface.</p>"},{"location":"user-guide/#4-interpreting-the-results","title":"4. Interpreting the Results","text":"<p>The JSON output from an analysis contains three main sections: <code>results</code>, <code>scorecard</code>, and <code>meta</code>.</p> <ul> <li><code>results</code>: A list where each item is the detailed output of a single test plugin. Key fields include:</li> <li><code>test_name</code>: The name of the test.</li> <li><code>status</code>: <code>completed</code>, <code>skipped</code>, or <code>error</code>.</li> <li><code>p_value</code>: The p-value from the statistical test. A low p-value (e.g., &lt; 0.01) suggests the data is not random according to this test. A value of <code>null</code> means the test is diagnostic and doesn't produce a p-value.</li> <li><code>fdr_rejected</code>: <code>true</code> if the test's p-value was deemed significant after correcting for multiple comparisons (False Discovery Rate). This is the primary indicator of a \"failed\" test.</li> <li> <p><code>metrics</code>: A dictionary of test-specific measurements and statistics.</p> </li> <li> <p><code>scorecard</code>: A high-level summary of the entire analysis.</p> </li> <li><code>failed_tests</code>: The number of tests where <code>fdr_rejected</code> was <code>true</code>. This is the most important summary metric.</li> <li><code>total_tests</code>: Total number of tests that were run.</li> <li> <p><code>p_value_distribution</code>: Statistics on the distribution of p-values from all statistical tests.</p> </li> <li> <p><code>meta</code>: Information about the analysis environment, including Python version, library versions, and a hash of the input data for reproducibility.</p> </li> </ul>"},{"location":"configs/","title":"Configuration Examples","text":"<p>This directory contains example configuration files for Pattern Analyzer in both <code>JSON</code> and <code>YAML</code> formats. These files demonstrate how to customize an analysis pipeline.</p>"},{"location":"configs/#files","title":"Files","text":"<ul> <li><code>example.json</code>: An example configuration using JSON syntax.</li> <li><code>example.yml</code>: An equivalent example using YAML syntax.</li> </ul>"},{"location":"configs/#configuration-structure","title":"Configuration Structure","text":"<p>You can use a configuration file with the CLI (<code>-c</code> or <code>--config</code> flag) or pass a dictionary with the same structure to the <code>engine.analyze()</code> method in the Python API.</p> <p>The main top-level keys are:</p> <ul> <li><code>transforms</code>: A list of data transformation plugins to apply sequentially before analysis. Each item can be a simple string (the plugin name) or a dictionary specifying a <code>name</code> and <code>params</code>.</li> <li><code>tests</code>: A list of test plugins to run on the (potentially transformed) data. The structure is the same as for <code>transforms</code>.</li> <li><code>fdr_q</code>: (Optional) A float between 0 and 1 specifying the significance level (q-value) for the False Discovery Rate (FDR) correction. This helps control for false positives when running multiple tests. Defaults to <code>0.05</code>.</li> <li><code>html_report</code>: (Optional) A file path where a standalone HTML report will be generated.</li> <li><code>log_path</code>: (Optional) A file path where detailed, structured (JSONL) logs will be written during the analysis.</li> </ul>"},{"location":"configs/#example-usage-cli","title":"Example Usage (CLI)","text":"<p>You can run an analysis using one of the example configuration files like this:</p> <pre><code># Using the YAML configuration\npatternanalyzer analyze my_data.bin --config docs/configs/example.yml\n\n# Using the JSON configuration\npatternanalyzer analyze my_data.bin --config docs/configs/example.json\n</code></pre>"}]}