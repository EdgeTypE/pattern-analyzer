import streamlit as st
import base64
import pandas as pd
import json
from patternlab.engine import Engine

st.set_page_config(page_title="PatternLab Analizi", layout="wide", page_icon="ğŸ”¬")

engine = Engine()

def run_analysis(config):
    # input_bytes'Ä± hesaplayalÄ±m
    input_bytes = b""
    if config.get('data', {}).get('file'):
        uploaded_file = config['data']['file']
        if uploaded_file is not None:
            input_bytes = uploaded_file.read()
    elif config.get('data', {}).get('text'):
        text = config['data']['text']
        if text:
            # Try to decode as base64, fallback to utf-8 encode
            try:
                input_bytes = base64.b64decode(text)
            except Exception:
                input_bytes = text.encode('utf-8')

    # engine.analyze Ã§aÄŸrÄ±sÄ± doÄŸru parametrelerle
    result = engine.analyze(input_bytes, config)
    st.session_state['analysis_result'] = result

def format_val(v, lang_code='tr', max_len=50):
    if v is None:
        return "None"
    if isinstance(v, dict):
        items = []
        for kk, vv in v.items():
            if isinstance(vv, (int, float)):
                items.append(f"{kk}: {vv}")
            else:
                items.append(f"{kk}: {str(vv)[:20]}...")
        val_str = ', '.join(items)
        if len(val_str) > max_len:
            val_str = val_str[:max_len] + '...'
        return val_str
    elif isinstance(v, list):
        return ', '.join(map(str, v))[:max_len] + '...' if len(', '.join(map(str, v))) > max_len else ', '.join(map(str, v))
    return str(v)

def main():
    # Language support
    if 'language' not in st.session_state:
        st.session_state.language = "tr"

    lang = {
        "tr": {
            "main_title": "ğŸ”¬ PatternLab Analiz Platformu",
            "main_desc": "Bu platform, verilerinizde rastgelelik paternlerini analiz etmek iÃ§in gÃ¼Ã§lÃ¼ istatistiksel testler sunar. Dosya yÃ¼kleyin veya doÄŸrudan veri girin ve kapsamlÄ± bir analiz raporu elde edin.",
            "results_title": "ğŸ“Š Analiz SonuÃ§larÄ±",
            "control_panel": "âš™ï¸ Kontrol Paneli",
            "file_tab": "ğŸ“ Dosya",
            "text_tab": "âœï¸ Metin",
            "file_label": "Dosya SeÃ§in",
            "file_help": "Limit 200MB per file â€¢ BIN, TXT, DAT",
            "text_label": "Veri Girin",
            "text_placeholder": "Base64 encoded data veya doÄŸrudan metin girin...",
            "test_selection": "ğŸ§ª Test SeÃ§imi",
            "tests_label": "Ã‡alÄ±ÅŸtÄ±rÄ±lacak Testler",
            "tests_help": "Ã‡alÄ±ÅŸtÄ±rÄ±lacak testleri seÃ§in. Her test, verinin rastgeleliÄŸini farklÄ± aÃ§Ä±lardan inceler. Ã–rneÄŸin, monobit testi 0 ve 1'lerin daÄŸÄ±lÄ±mÄ±nÄ± kontrol eder.",
            "all_tests": "TÃ¼m Testleri SeÃ§",
            "no_tests": "HiÃ§bir Test SeÃ§me",
            "transform_selection": "ğŸ”„ Transform SeÃ§imi",
            "transforms_label": "Uygulanacak Transformlar",
            "transforms_help": "Uygulanacak transformlarÄ± seÃ§in. Transformlar, veriyi dÃ¶nÃ¼ÅŸtÃ¼rerek testlerin hassasiyetini artÄ±rabilir, Ã¶rneÄŸin XOR ile ÅŸifreleme paternlerini kÄ±rar.",
            "all_transforms": "TÃ¼m TransformlarÄ± SeÃ§",
            "no_transforms": "HiÃ§bir Transform SeÃ§me",
            "analysis_settings": "âš™ï¸ Analiz AyarlarÄ±",
            "fdr_label": "FDR AnlamlÄ±lÄ±k DÃ¼zeyi (q)",
            "fdr_help": "FDR (False Discovery Rate) anlamlÄ±lÄ±k dÃ¼zeyi. DÃ¼ÅŸÃ¼k deÄŸer (Ã¶r. 0.05) daha katÄ± test anlamÄ±na gelir; p-value < q ise test baÅŸarÄ±sÄ±z sayÄ±lÄ±r.",
            "start_analysis": "ğŸš€ Analizi BaÅŸlat",
            "clear": "ğŸ—‘ï¸ Temizle",
            "analyzing": "Analiz yapÄ±lÄ±yor...",
            "analysis_error": "Analiz hatasÄ±: {error}",
            "scorecard": "Scorecard",
            "findings": "Bulgular",
            "select_result": "Bir sonuÃ§ seÃ§in",
            "selected_details": "SeÃ§ilen Sonucun DetaylarÄ±",
            "visuals": "GÃ¶rseller",
            "visual_error": "GÃ¶rsel gÃ¶sterilemedi ({name}): {error}",
            "visual_format_error": "GÃ¶rsel formatÄ± yanlÄ±ÅŸ: {name}",
            "no_results": "Analiz sonucu boÅŸ veya yok.",
            "language": "Dil",
            "failed_tests": "BaÅŸarÄ±sÄ±z Testler",
            "mean_effect_size": "Ortalama Etki Boyutu",
            "mean_effect_size_desc": "Testlerin etki boyutlarÄ±nÄ±n ortalamasÄ± (Ã¶r. sapma miktarÄ±). None ise yeterli veri yok veya hesaplanmadÄ±.",
            "p_value_distribution": "P-DeÄŸeri DaÄŸÄ±lÄ±mÄ±",
            "p_value_distribution_desc": "P-deÄŸerlerinin istatistikleri (adet, ortalama, medyan vb.). Rastgele veride p-deÄŸerleri uniform daÄŸÄ±lÄ±mlÄ± olmalÄ±.",
            "total_tests": "Toplam Testler",
            "fdr_q": "FDR q",
            "skipped_tests": "Atlanan Testler",
            "skipped_tests_desc": "Atlanan testler: Veri boyutu yetersiz veya Ã¶nkoÅŸullar saÄŸlanmadÄ±. Detaylar sonuÃ§ tablosunda 'reason' sÃ¼tununda.",
            "run_tests": "Ã‡alÄ±ÅŸtÄ±rÄ±lan Testler",
            "test_explanations": {
                "monobit": "Monobit testi: Verideki 0 ve 1'lerin sayÄ±sÄ±nÄ± kontrol eder. Rastgele veride yaklaÅŸÄ±k eÅŸit olmalÄ±.",
                "approximate_entropy": "Approximate Entropy: Verinin tahmin edilemezliÄŸini Ã¶lÃ§er. DÃ¼ÅŸÃ¼k entropi dÃ¼zenli patern gÃ¶sterir.",
                "autocorrelation": "Autocorrelation: Verinin kendisiyle gecikmeli korelasyonunu hesaplar. YÃ¼ksek deÄŸer periyodiklik belirtir.",
                "autoencoder_anomaly": "Autoencoder Anomaly: Makine Ã¶ÄŸrenmesiyle anomalileri tespit eder.",
                "binary_matrix_rank": "Binary Matrix Rank: Matris rank testi, lineer baÄŸÄ±mlÄ±lÄ±klarÄ± kontrol eder.",
                "block_frequency": "Block Frequency: Bloklardaki frekans daÄŸÄ±lÄ±mÄ±nÄ± test eder.",
                "classifier_labeler": "Classifier Labeler: SÄ±nÄ±flandÄ±rÄ±cÄ± ile veriyi etiketler.",
                "conditional_entropy": "Conditional Entropy: KoÅŸullu entropi, baÄŸÄ±mlÄ±lÄ±klarÄ± Ã¶lÃ§er.",
                "cusum": "Cumulative Sums: KÃ¼mÃ¼latif toplam testi, sapmalarÄ± tespit eder.",
                "dft_spectral_advanced": "DFT Spectral Advanced: Spektral analiz, frekans paternlerini arar.",
                "diehard_3d_spheres": "Diehard 3D Spheres: 3D kÃ¼re testi (veri yetersizse hata verir).",
                # DiÄŸer testler iÃ§in benzer aÃ§Ä±klamalar ekleyin...
                # (TÃ¼m testler iÃ§in eklemek ideal, ama Ã¶rnek olarak birkaÃ§ tane)
            },
            "column_explanations": {
                "test_name": "Test adÄ±",
                "passed": "GeÃ§ti mi? (True: Rastgelelik kabul edildi)",
                "p_value": "P-deÄŸeri: DÃ¼ÅŸÃ¼kse (<0.05) veri rastgele deÄŸil. None ise test p-value Ã¼retmedi (betimsel test).",
                "p_values": "Alt p-deÄŸerleri (Ã§oklu alt-test varsa).",
                "effect_sizes": "Etki boyutu: Sapma miktarÄ±.",
                "flags": "Ek bayraklar.",
                "z_score": "Z-skoru: Standart sapma cinsinden sapma.",
                "evidence": "KanÄ±t/ek detaylar.",
                "time_ms": "Ä°ÅŸlem sÃ¼resi (ms).",
                "bytes_processed": "Ä°ÅŸlenen bayt miktarÄ±.",
                "status": "Durum: completed (tamamlandÄ±), skipped (atlandÄ±), error (hata).",
                "fdr_rejected": "FDR ile reddedildi mi?",
                "fdr_q": "FDR eÅŸiÄŸi.",
                "visuals": "GÃ¶rseller (eÄŸer varsa).",
                "reason": "Atlanma veya hata nedeni (Ã¶r. yetersiz veri).",
                "metrics": "Ek metrikler.",
            }
        },
        "en": {
            # Ä°ngilizce karÅŸÄ±lÄ±klarÄ±nÄ± ekleyin...
            "main_title": "ğŸ”¬ PatternLab Analysis Platform",
            # ... diÄŸerleri
            "test_explanations": {
                "monobit": "Monobit test: Checks the proportion of 0s and 1s. Should be approximately equal in random data.",
                # ... diÄŸerleri
            },
            "column_explanations": {
                "test_name": "Test name",
                "passed": "Passed? (True: Randomness accepted)",
                "p_value": "P-value: Low (<0.05) means non-random. None if test doesn't produce p-value (descriptive).",
                # ... diÄŸerleri
            }
        }
    }[st.session_state.language]

    # Main content
    st.markdown(f"""
        <h1 id="pattern-lab-analiz-platformu">{lang['main_title']}</h1>
    """, unsafe_allow_html=True)
    st.write(lang['main_desc'])
    st.markdown(f"""
        <h2 id="analiz-sonuclari">{lang['results_title']}</h2>
    """, unsafe_allow_html=True)

    # Sidebar
    with st.sidebar:
        # Language selector
        selected_lang = st.selectbox(lang['language'], options=["tr", "en"], format_func=lambda x: "TÃ¼rkÃ§e" if x == "tr" else "English", index=0 if st.session_state.language == "tr" else 1)
        if selected_lang != st.session_state.language:
            st.session_state.language = selected_lang
            st.rerun()

        st.header(lang['control_panel'])
        st.divider()

        # Tabs for input
        tab1, tab2 = st.tabs([lang['file_tab'], lang['text_tab']])

        with tab1:
            uploaded_file = st.file_uploader(
                lang['file_label'],
                type=['bin', 'txt', 'dat'],
                help=lang['file_help']
            )

        with tab2:
            text_input = st.text_area(
                lang['text_label'],
                placeholder=lang['text_placeholder'],
                height=100
            )

        st.subheader(lang['test_selection'])
        available_tests = engine.get_available_tests()
        default_tests = ["monobit", "approximate_entropy", "autocorrelation"]  # From HTML

        if 'selected_tests' not in st.session_state:
            st.session_state.selected_tests = [t for t in default_tests if t in available_tests]

        selected_tests = st.multiselect(
            lang['tests_label'],
            options=available_tests,
            default=st.session_state.selected_tests,
            help=lang['tests_help']
        )

        # Test aÃ§Ä±klamalarÄ± iÃ§in expander
        with st.expander("Test AÃ§Ä±klamalarÄ±"):
            for test in available_tests:
                desc = lang['test_explanations'].get(test, "AÃ§Ä±klama yok.")
                st.write(f"**{test}**: {desc}")

        col1, col2 = st.columns(2)
        with col1:
            if st.button(lang['all_tests']):
                st.session_state.selected_tests = available_tests
                st.rerun()
        with col2:
            if st.button(lang['no_tests']):
                st.session_state.selected_tests = []
                st.rerun()

        st.subheader(lang['transform_selection'])
        available_transforms = engine.get_available_transforms()

        if 'selected_transforms' not in st.session_state:
            st.session_state.selected_transforms = []

        selected_transforms = st.multiselect(
            lang['transforms_label'],
            options=available_transforms,
            default=st.session_state.selected_transforms,
            help=lang['transforms_help']
        )

        col3, col4 = st.columns(2)
        with col3:
            if st.button(lang['all_transforms']):
                st.session_state.selected_transforms = available_transforms
                st.rerun()
        with col4:
            if st.button(lang['no_transforms']):
                st.session_state.selected_transforms = []
                st.rerun()

        st.subheader(lang['analysis_settings'])
        fdr_q = st.slider(
            lang['fdr_label'],
            min_value=0.01,
            max_value=0.10,
            value=0.05,
            step=0.01,
            format="%.2f",
            help=lang.get('fdr_help', '')
        )

        col5, col6 = st.columns(2)
        with col5:
            start_button = st.button(lang['start_analysis'], type="primary")
        with col6:
            clear_button = st.button(lang['clear'], type="secondary")

    # Handle buttons
    if clear_button:
        st.session_state.pop('analysis_result', None)
        st.session_state.pop('selected_tests', None)
        st.session_state.pop('selected_transforms', None)
        st.rerun()

    if start_button:
        # Update session state
        st.session_state.selected_tests = selected_tests
        st.session_state.selected_transforms = selected_transforms

        # Build config
        config = {
            'data': {
                'file': uploaded_file,
                'text': text_input,
            },
            'tests': [{'name': t, 'params': {}} for t in selected_tests],
            'transforms': [{'name': tr, 'params': {}} for tr in selected_transforms],
            'fdr_q': fdr_q,
        }

        with st.spinner(lang['analyzing']):
            try:
                run_analysis(config)
            except Exception as e:
                st.error(lang['analysis_error'].format(error=str(e)))
                st.session_state['analysis_result'] = {"error": str(e)}

    # Display results if available
    if 'analysis_result' in st.session_state:
        result = st.session_state['analysis_result']
        if isinstance(result, dict) and 'error' in result:
            st.error(result['error'])
        else:
            # Compute additional stats
            results = result.get('results', []) if isinstance(result, dict) else []
            total_tests = len(results)
            run_tests = sum(1 for r in results if r.get('status') != 'skipped')
            skipped_tests = total_tests - run_tests
            failed_tests = sum(1 for r in results if not r.get('passed', True) and r.get('status') != 'skipped')

            # scorecard'Ä± st.metric ile gÃ¶ster
            scorecard = result.get('scorecard', {}) if isinstance(result, dict) else {}
            if scorecard:
                st.subheader(lang['scorecard'])
                # Custom metrics
                cols = st.columns(5)
                cols[0].metric(lang['failed_tests'], f"{failed_tests} / {total_tests}")
                cols[1].metric(lang['mean_effect_size'], format_val(scorecard.get('mean_effect_size', 'None')), help=lang.get('mean_effect_size_desc', ''))
                cols[2].metric(lang['p_value_distribution'], format_val(scorecard.get('p_value_distribution', {}), max_len=40), help=lang.get('p_value_distribution_desc', ''))
                cols[3].metric(lang['run_tests'], run_tests)
                cols[4].metric(lang['skipped_tests'], skipped_tests, help=lang.get('skipped_tests_desc', ''))

            if results:
                st.subheader(lang['findings'])
                df = pd.DataFrame(results)
                # Reindex to include all possible columns
                expected_columns = [
                    'test_name', 'passed', 'p_value', 'p_values', 'effect_sizes', 'flags',
                    'z_score', 'evidence', 'time_ms', 'bytes_processed', 'status',
                    'fdr_rejected', 'fdr_q', 'visuals', 'reason', 'metrics'
                ]
                df = df.reindex(columns=expected_columns)
                # Do not stringify metrics, let dataframe handle
                if 'p_value' in df.columns:
                    def _p_style(v):
                        try:
                            return 'background-color: red' if float(v) < fdr_q else ''
                        except Exception:
                            return ''
                    styled = df.style.applymap(_p_style, subset=['p_value'])
                    st.dataframe(styled, column_config={
                        col: st.column_config.TextColumn(help=lang['column_explanations'].get(col, '')) for col in expected_columns
                    })
                else:
                    st.dataframe(df, column_config={
                        col: st.column_config.TextColumn(help=lang['column_explanations'].get(col, '')) for col in expected_columns
                    })

                # Select a result for details
                option_labels = [f"{i} - {r.get('test_name', 'Unknown')}" for i, r in enumerate(results)]
                selected_label = st.selectbox(lang['select_result'], options=option_labels)
                if selected_label:
                    selected_idx = int(selected_label.split(" - ")[0])
                    selected_result = results[selected_idx]
                    st.subheader(lang['selected_details'])
                    st.json(selected_result)

                    # Test-specific explanation
                    test_name = selected_result.get('test_name')
                    desc = lang['test_explanations'].get(test_name, "AÃ§Ä±klama yok.")
                    st.write(f"**Test AÃ§Ä±klamasÄ±**: {desc}")

                    # If skipped or error, show reason
                    status = selected_result.get('status')
                    if status == 'skipped' or status == 'error':
                        reason = selected_result.get('reason', 'Bilinmeyen neden')
                        st.warning(f"Bu test {status} oldu. Neden: {reason}")

                    # Visuals if any
                    visuals = selected_result.get('visuals', {})
                    if visuals:
                        st.subheader(lang['visuals'])
                        for vname, vdata in visuals.items():
                            if isinstance(vdata, dict):
                                if 'data_base64' in vdata:
                                    try:
                                        mime = vdata.get('mime', 'image/svg+xml')
                                        img_data = base64.b64decode(vdata['data_base64'])
                                        st.image(img_data, caption=vname, use_column_width=True)
                                    except Exception as e:
                                        st.error(lang['visual_error'].format(name=vname, error=str(e)))
                                elif 'path' in vdata:
                                    try:
                                        st.image(vdata['path'], caption=vname, use_column_width=True)
                                    except Exception as e:
                                        st.error(lang['visual_error'].format(name=vname, error=str(e)))
                            else:
                                st.write(lang['visual_format_error'].format(name=vname))
            else:
                st.info(lang['no_results'])

if __name__ == "__main__":
    main()